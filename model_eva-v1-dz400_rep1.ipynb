{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist import Rays_GoldenSpiral\n",
    "from stardist.models import Config3D, StarDist3D, StarDistData3D\n",
    "\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ\n",
    "\n",
    "def allocateOnEmptyGPU():\n",
    "    import os\n",
    "    import re\n",
    "    import numpy as np\n",
    "    from subprocess import check_output\n",
    "\n",
    "    nvidia_smi_output = check_output(['nvidia-smi']).decode(\"utf-8\")\n",
    "    memory_matches = re.findall('\\d+MiB\\s*/\\s*\\d+MiB', nvidia_smi_output)\n",
    "    memory_string = [match.split('MiB')[0] for match in memory_matches]\n",
    "    gpu_memory_usage = list(map(int, memory_string))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(np.argmin(gpu_memory_usage))\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    print('Run on GPU with ID: {}'.format(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "\n",
    "    return\n",
    "\n",
    "allocateOnEmptyGPU()\n",
    "\n",
    "X_trn_paths = sorted(Path(r'Y:\\Eric\\2021_Iterative_Biofilm_Annotation\\datasets\\eva-v1-dz400\\train\\images').glob('*.tif'))\n",
    "X_vld_paths = sorted(Path(r'Y:\\Eric\\2021_Iterative_Biofilm_Annotation\\datasets\\eva-v1-dz400\\valid\\images').glob('*.tif'))\n",
    "\n",
    "for p in X_trn_paths:\n",
    "    print(p)\n",
    "    \n",
    "for p in X_vld_paths:\n",
    "    print(p)\n",
    "\n",
    "X_trn = [imread(p) for p in tqdm(X_trn_paths)]\n",
    "X_vld = [imread(p) for p in tqdm(X_vld_paths)]\n",
    "\n",
    "\n",
    "Y_trn_paths = sorted(Path(r'Y:\\Eric\\2021_Iterative_Biofilm_Annotation\\datasets\\eva-v1-dz400\\train\\masks').glob('*.tif'))\n",
    "Y_vld_paths = sorted(Path(r'Y:\\Eric\\2021_Iterative_Biofilm_Annotation\\datasets\\eva-v1-dz400\\valid\\masks').glob('*.tif'))\n",
    "\n",
    "for p in Y_trn_paths:\n",
    "    print(p)\n",
    "    \n",
    "for p in Y_vld_paths:\n",
    "    print(p)\n",
    "\n",
    "Y_trn = [imread(p) for p in tqdm(Y_trn_paths)]\n",
    "Y_vld = [imread(p) for p in tqdm(Y_vld_paths)]\n",
    "\n",
    "X_trn[2] = X_trn[2][1:]\n",
    "\n",
    "for y, x in zip(Y_trn, X_trn):\n",
    "    print(y.shape, x.shape)\n",
    "\n",
    "#X_trn, Y_trn, X_vld, Y_vld = tuple([x[:64, :128, :128] for x in X] for X in [X_trn, Y_trn, X_vld, Y_vld])\n",
    "\n",
    "#for y, x in zip(Y_trn, X_trn):\n",
    "#    print(y.shape, x.shape)\n",
    "\n",
    "modelname = 'eva-v1_dz400_rep1'\n",
    "basedir = 'models'\n",
    "n_rays = 192\n",
    "del_empty_patches = False\n",
    "percentage = 100\n",
    "train_patch_size = (64, 192, 192)\n",
    "\n",
    "    axis_norm = (0, 1, 2)\n",
    "    X_trn= [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_trn)]\n",
    "    X_vld= [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X_vld)]\n",
    "\n",
    "    n_channel = 1\n",
    "\n",
    "    extents = calculate_extents(Y_trn[2])\n",
    "    anisotropy = tuple(np.max(extents) / extents)\n",
    "\n",
    "anisotropy\n",
    "\n",
    "use_gpu = gputools_available()\n",
    "\n",
    "use_gpu = gputools_available()\n",
    "\n",
    "def random_fliprot(img, mask, axis=None): \n",
    "    if axis is None:\n",
    "        axis = tuple(range(mask.ndim))\n",
    "    axis = tuple(axis)\n",
    "            \n",
    "    assert img.ndim>=mask.ndim\n",
    "    perm = tuple(np.random.permutation(axis))\n",
    "    transpose_axis = np.arange(mask.ndim)\n",
    "    for a, p in zip(axis, perm):\n",
    "        transpose_axis[a] = p\n",
    "    transpose_axis = tuple(transpose_axis)\n",
    "    img = img.transpose(transpose_axis + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(transpose_axis) \n",
    "    for ax in axis: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    # Note that we only use fliprots along axis=(1,2), i.e. the yx axis \n",
    "    # as 3D microscopy acquisitions are usually not axially symmetric\n",
    "    x, y = random_fliprot(x, y, axis=(1,2))\n",
    "    x = random_intensity_change(x)\n",
    "    return x, y\n",
    "\n",
    "    # Predict on subsampled grid for increased efficiency and larger field of view\n",
    "    grid = tuple(1 if a > 1.5 else 2 for a in anisotropy)\n",
    "\n",
    "    # Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n",
    "    rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n",
    "\n",
    "    conf = Config3D (\n",
    "        rays=rays,\n",
    "        grid=grid,\n",
    "        anisotropy=anisotropy,\n",
    "        use_gpu=use_gpu,\n",
    "        n_channel_in=n_channel,\n",
    "        # adjust for your data below (make patch size as large as possible)\n",
    "        train_patch_size=train_patch_size,\n",
    "        train_batch_size=1,\n",
    "    )\n",
    "    vars(conf)\n",
    "\n",
    "    if use_gpu:\n",
    "        from csbdeep.utils.tf import limit_gpu_memory\n",
    "        # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "        limit_gpu_memory(0.75, total_memory=10000)\n",
    "\n",
    "    model = StarDist3D(conf,\n",
    "                       name=modelname,\n",
    "                       basedir=basedir)\n",
    "\n",
    "    fov = np.array(model._axes_tile_overlap('ZYX'))\n",
    "\n",
    "    median_size = calculate_extents(Y_trn, np.median)\n",
    "\n",
    "    if any(median_size > fov):\n",
    "        print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "\n",
    "    model.train(X_trn, Y_trn,\n",
    "                validation_data=(X_vld, Y_vld),\n",
    "                epochs=400,\n",
    "                augmenter=augmenter)\n",
    "\n",
    "model.optimize_thresholds(X_vld, Y_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
