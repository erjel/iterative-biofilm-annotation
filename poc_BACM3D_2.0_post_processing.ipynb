{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict input data with CARE networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://github.com/CSBDeep/CSBDeep/blob/master/examples/denoising3D/3_prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict \"distance to nearest cell exterior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread, imwrite\n",
    "from csbdeep.models import CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'care_bcm3d_target1_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imread('training_data/full_semimanual-raw/test/images/im0.tif')\n",
    "axes = 'ZYX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=None, name=modelname, basedir='models')\n",
    "restored = model.predict(x, axes,n_tiles=(4, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite('distance_to_nearest_cell_exterior.tif', restored, compression='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict \"proximity enhanced cell boundary\"\n",
    "\n",
    "-> Restart Kernel to clean GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread, imwrite\n",
    "from csbdeep.models import CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'care_bcm3d_target2_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imread('training_data/full_semimanual-raw/test/images/im0.tif')\n",
    "axes = 'ZYX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=None, name=modelname, basedir='models')\n",
    "restored = model.predict(x, axes,n_tiles=(4, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite('proximity_enhanced_cell_boundary.tif', restored, compression='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread, imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import binary_erosion, grey_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = imread('distance_to_nearest_cell_exterior.tif')\n",
    "target2 = imread('proximity_enhanced_cell_boundary.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img_stack: np.ndarray, low=3, high=99.9) -> np.ndarray:\n",
    "    p_low, p_high = np.percentile(img_stack, [low, high])\n",
    "    return (img_stack - p_low) / (p_high - p_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing of \"distance to nearest cell exterior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target1[16, 256:-256, 256:-256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted ‘distance to nearest cell exterior’ images were first normalized by a simple percentile-based normalization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_normalized = normalize(target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying Otsu-thresholding to the ‘distance to nearest cell exterior’ image to obtain a binary image (Figure S3b), connected voxel clusters can be isolated and identified assingle cell objects by labeling connected regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = threshold_otsu(target1_normalized)\n",
    "target1_binarized_ = target1_normalized > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split clusters that are only connected by one or two voxels, the boundary voxels of each object were set to zero before labeling connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_binarized = binary_erosion(target1_binarized_)\n",
    "target1_labels = label(target1_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "ax1.hist(target1_normalized.flatten(), 100, label='Normalized target1');\n",
    "ylim = ax1.get_ylim()\n",
    "ax1.plot([thresh, thresh], ylim, 'r', label='Otsu_threshold')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(ylim)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.imshow(target1_binarized_[16, 256:-256, 256:-256])\n",
    "\n",
    "ax3.imshow(target1_binarized_[16, 256:-256, 256:-256])\n",
    "\n",
    "ax4.imshow(target1_labels[16, 256:-256, 256:-256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labeling, the erased boundary voxels were added back to each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_labels = grey_dilation(target1_labels, size=(2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target1_labels[16, 256:-256, 256:-256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A conservative size-exclusion filter was applied: small objects with volume smaller than the radius cubed of the targeted cells were considered background noise and filtered out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* voxel size 400 nm x 63nm x 63 nm\n",
    "* radius: 0.2775 um Hartmann *et al.* **Nature Physics** (2019)\n",
    "\n",
    "$r^3 = 0.0213 um^3$\n",
    "\n",
    "$V(vx) = 0.4 nm \\times 0.063 nm \\times 0.063 nm = 0.0015876 um^3$\n",
    "\n",
    "$V(thresh) = 0.0213 / 0.0015 =  14.2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops(target1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = np.array([p.area for p in props])\n",
    "v_thresh = 14.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1,1)\n",
    "ax1.hist(volumes, 100, label='Target1 volumes');\n",
    "y_lim = ax1.get_ylim()\n",
    "ax1.plot([v_thresh, v_thresh], y_lim, 'r', label='volume threshold')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_labels = np.array([p.label for p in props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.arange(np.max(target1_labels) + 1, dtype=target1_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut[obj_labels[volumes <= v_thresh]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_labels = lut[target1_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "props = regionprops(target1_labels)\n",
    "assert all(np.array([p.area for p in props]) > v_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing with \"proximity enhanced cell boundary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects that need further processing were found by evaluating its volume and solidity, i.e., the volume to convex volume ratio. Here, volume is defined as the number of voxels occupied by an object. Convex volume is defined as the number of voxels of a convex hull, which is the smallest convex polygon that encloses an object. The upper limit was found by using the interquartile rule, i.e. the upper limit is quartile 3 (Q3) plus 1.5 times interquartile range (IQR). If an object's volume or solidity is larger than the upper limit, it will be singled out for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops(target1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solidity = np.array([p.solidity for p in props])\n",
    "volume = np.array([p.area for p in props])\n",
    "labels = np.array([p.label for p in props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_thresh = np.percentile(volume, 75) + 1.5 * iqr(volume)\n",
    "s_thresh = np.percentile(solidity, 25) - 1.5 * iqr(solidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.hist(volume, 100, label='Volume distribution');\n",
    "ax1.set_xlabel('volume')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.plot([v_thresh, v_thresh], [0, 400], 'r', label='volume threshold')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.hist(solidity, 100, label='Solidity distribution');\n",
    "ax2.plot([s_thresh, s_thresh], [0, 400], 'r', label='volume threshold')\n",
    "ax2.set_xlabel('solidity')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For me it looks like the radius threshold is not high enough**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why are there so many 1.0 values in the solidity?**\n",
    "\n",
    "**It does not make sense to me to use the solidty threshold on 3 quartile of volume/ convex volume. It is probably better to apply it on the lower range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels = labels[(solidity < s_thresh) & (volume > v_thresh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(undersegmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.zeros(np.max(target1_labels) + 1,dtype=target1_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut[undersegmented_labels] = undersegmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_undersegmented = lut[target1_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these objects together generate a new binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filterd = target1_undersegmented > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-produced ‘proximity enhanced cell boundary’ images were first normalized by the same percentile-based normalization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2_normalized = normalize(target2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we generated a difference map by subtracting the ‘proximity enhanced cell boundary’ image from the ‘distance to nearest cell exterior’ image and then set all negative valued voxels to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = target1_mormalized - target2_mormalized\n",
    "factor[factor < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference map was then multiplied by the binary image generated in Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = labels_filterd * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_filtered[16, 256:-256, 256:-256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = filters.threshold_otsu(labels_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_filtered.flatten(), 100)\n",
    "plt.plot([thresh, thresh], [0, 10_000], 'r')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed = labels_filtered > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(watershed_seed[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_labels = label(watershed_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops(watershed_seed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = np.array([p.area for p in props])\n",
    "seed_labels = np.array([p.label for p in props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(volumes, 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.arange(watershed_seed_labels.max() + 1, dtype=watershed_seed_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut[seed_labels[volumes < 30]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lut[watershed_seed_labels] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_ = watershed_seed.copy()\n",
    "watershed_seed_[~mask] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = regionprops(label(watershed_seed_ > thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_ = np.array([p.area for p in props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(volume_, h[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(watershed_seed_[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_filtered[16, 512-128:512+256, 512-128:512+256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_result = watershed(\n",
    "    -labels_filtered,\n",
    "    markers=label(watershed_seed_ > thresh),\n",
    "    mask=target1_undersegmented > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ws_result[16, 512-128:512+256, 512-128:512+256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_props = regionprops(ws_result)\n",
    "\n",
    "ws_solidity = np.array([p.solidity for p in ws_props])\n",
    "ws_volume = np.array([p.area for p in ws_props])\n",
    "ws_labels = np.array([p.label for p in ws_props])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ws_solidity, 100);\n",
    "plt.plot([s_thresh, s_thresh], [0, 12], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ws_volume, 100);\n",
    "plt.plot([v_thresh, v_thresh], [0, 12], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels1 = ws_labels[(ws_solidity < s_thresh) & (ws_volume > v_thresh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Otsu threshold watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_multiotsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, thresh1, thresh2 = threshold_multiotsu(labels_filtered, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_filtered.flatten(), 100);\n",
    "plt.yscale('log')\n",
    "plt.plot([thresh1, thresh1], [0, 10_000], 'r', label='thresh1')\n",
    "plt.plot([thresh2, thresh2], [0, 10_000], 'b', label='thresh2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the improvement so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seeds1 = labels_filtered > thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_labels1 = label(watershed_seeds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete again small watershed seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props1 = regionprops(watershed_seed_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes1 = np.array([p.area for p in props1]) \n",
    "labels1 = np.array([p.label for p in props1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = plt.hist(volumes1, 100)\n",
    "plt.plot([30, 30], [0, 70], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(volumes1 < 30), len(volumes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete seeds which are below the volume threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.arange(watershed_seed_labels.max()+1, dtype=watershed_seed_labels1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut[labels1[volumes1 < 30]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_labels = lut[watershed_seed_labels1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.zeros(ws_result.max()+1, dtype=ws_result.dtype)\n",
    "lut[undersegmented_labels1] = undersegmented_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_results_ = lut[ws_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_result1 = watershed(\n",
    "    -labels_filtered,\n",
    "    markers=watershed_seed_labels,\n",
    "    mask=ws_results_ > 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_props2 = regionprops(ws_result1)\n",
    "\n",
    "ws_solidity2 = np.array([p.solidity for p in ws_props2])\n",
    "ws_volume2 = np.array([p.area for p in ws_props2])\n",
    "ws_labels2 = np.array([p.label for p in ws_props2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels2 = ws_labels2[(ws_solidity2 < s_thresh) & (ws_volume2 > v_thresh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seeds2 = labels_filtered > thresh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_labels2 = label(watershed_seeds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props2 = regionprops(watershed_seed_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes2 = np.array([p.area for p in props2]) \n",
    "labels2 = np.array([p.label for p in props2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.arange(watershed_seed_labels2.max()+1, dtype=watershed_seed_labels2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut[labels2[volumes2 < 30]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_seed_labels2 = lut[watershed_seed_labels2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = np.zeros(ws_result1.max()+1, dtype=ws_result1.dtype)\n",
    "lut[undersegmented_labels2] = undersegmented_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_results1_ = lut[ws_result1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_result2 = watershed(\n",
    "    -labels_filtered,\n",
    "    markers=watershed_seed_labels2,\n",
    "    mask=ws_results1_ > 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_props3 = regionprops(ws_result2)\n",
    "\n",
    "ws_solidity3 = np.array([p.solidity for p in ws_props3])\n",
    "ws_volume3 = np.array([p.area for p in ws_props3])\n",
    "ws_labels3 = np.array([p.label for p in ws_props3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels3 = ws_labels3[(ws_solidity3 < s_thresh) & (ws_volume3 > v_thresh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersegmented_labels3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the watershed segmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import relabel_sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target1_labels`-> Results of the direct connected components\n",
    "\n",
    "`ws_result` -> Result of the single otsu threshold watershed\n",
    "\n",
    "`ws_result1`-> Result of the first 5 class otsu threshold watershed\n",
    "\n",
    "`ws_result2` ->  Result of the second 5 clss otsu threshold watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: If the watershed mask was applied correctly, the watershed results do not overlap with the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not any(np.unique(target1_labels[ws_result2 > 0]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not any(np.unique(target1_labels[ws_result1 > 0]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not any(np.unique(target1_labels[ws_result > 0]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels = target1_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A conservative size-exclusion filter was applied: small objects with volume 10 times smaller than the upper limit volume were considered unreasonable small parts and filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "import numpy as np\n",
    "\n",
    "def delete_small_objects(label_stack: np.ndarray, thresh: Optional[float] = v_thresh/10) -> np.ndarray:\n",
    "    props = regionprops(label_stack)\n",
    "    volumes = np.array([p.area for p in props])\n",
    "    labels = np.array([p.label for p in props])\n",
    "\n",
    "    lut = np.arange(label_stack.max()+1, dtype=label_stack.dtype)\n",
    "    lut[labels[volumes < thresh]] = 0\n",
    "    \n",
    "    return lut[label_stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_result = delete_small_objects(ws_result)\n",
    "ws_result1 = delete_small_objects(ws_result1)\n",
    "ws_result2 = delete_small_objects(ws_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels += (result_labels.max() * (ws_result > 0)) + ws_result\n",
    "result_labels += (result_labels.max() * (ws_result1 > 0)) + ws_result1\n",
    "result_labels += (result_labels.max() * (ws_result2 > 0)) + ws_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ‘distance to nearest cell exterior’ images were confined to the cell interior, we dilated each object by 1-2 voxels to increase the cell volumes using standard morphological dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels = grey_dilation(result_labels, size=(3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels, _, _ = relabel_sequential(result_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite('bcm3d_2.0.tif', result_labels, compression='zlib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
