{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "from edt import edt\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, grey_closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcm3d_targets(labels: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    euclidian_dist = edt(labels)\n",
    "    binary_mask = labels > 0\n",
    "    \n",
    "    next_cell_dist_ = np.zeros_like(euclidian_dist)\n",
    "    \n",
    "    label_vals = np.unique(labels)\n",
    "    label_vals = label_vals[label_vals != 0]\n",
    "    \n",
    "    for v in label_vals:\n",
    "        mask = labels == v\n",
    "        \n",
    "        selection = euclidian_dist[mask]\n",
    "        euclidian_dist[mask] = selection / selection.max()\n",
    "        \n",
    "        labels_ = np.ones_like(next_cell_dist_)\n",
    "        labels_[binary_mask] = 0\n",
    "        labels_[mask] = 1\n",
    "        proximity = edt(labels_)\n",
    "        next_cell_dist_[mask] = 1/proximity[mask]        \n",
    "    \n",
    "    cell_ext_dist = euclidian_dist ** 3\n",
    "    next_cell_dist = binary_mask - euclidian_dist\n",
    "    \n",
    "    # Note(erjel): Paper describes Gaussian blur with simga = (5,5,5)\n",
    "    cell_ext_dist = gaussian_filter(cell_ext_dist, sigma=(2,2,2))\n",
    "        \n",
    "    next_cell_dist *= next_cell_dist_\n",
    "    \n",
    "    # Note(erjel): Unclear kernel size for grey closing in paper\n",
    "    next_cell_dist = grey_closing(next_cell_dist, size=(2,2,2))\n",
    "    # Note(erjel): Paper describes Gaussian blur with simga = (5,5,5)\n",
    "    next_cell_dist = gaussian_filter(next_cell_dist, sigma=(2,2,2))\n",
    "    \n",
    "    return cell_ext_dist, next_cell_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = imread('training_data/patches-semimanual-raw-64x128x128/train/masks/im1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = bcm3d_targets(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [imread(p) for p in sorted(Path('training_data/patches-semimanual-raw-64x128x128/train/masks').glob('*.tif'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(labels)\n",
    "with tqdm(total=l) as pbar:\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(bcm3d_targets, arg): arg for arg in labels}\n",
    "        results = {}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            arg = futures[future]\n",
    "            results[arg] = future.result()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "from csbdeep.utils import normalize\n",
    "from csbdeep.data import shuffle_inplace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from iterative_biofilm_annotation.unet.utils import crop, SegConfig, CustomDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.models import BaseModel\n",
    "from csbdeep.data import PadAndCropResizer\n",
    "from csbdeep.internals.nets import common_unet\n",
    "from csbdeep.utils.tf import CARETensorBoardImage\n",
    "\n",
    "from csbdeep.utils.tf import keras_import\n",
    "\n",
    "keras = keras_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCM3DModel(BaseModel):    \n",
    "    @property\n",
    "    def _config_class(self):\n",
    "        return SegConfig\n",
    "    \n",
    "    def _build(self):\n",
    "        return common_unet(n_dim=3, n_depth=self.config.unet_depth,\n",
    "                           n_first=32, residual=True,\n",
    "                           last_activation='linear',\n",
    "                           n_channel_out=self.config.n_channel_out)((None,None,None,self.config.n_channel_in))\n",
    "\n",
    "    def _prepare_for_training(self, validation_data, lr):      \n",
    "        self.keras_model.compile(optimizer=keras.optimizers.Adam(lr),\n",
    "                                 loss=keras.losses.MeanAbsoluteError(),\n",
    "                                 metrics=['mae','accuracy'])\n",
    "        self.callbacks = self._checkpoint_callbacks()\n",
    "        self.callbacks.append(keras.callbacks.TensorBoard(log_dir=str(self.logdir/'logs'),\n",
    "                                                          write_graph=False, profile_batch=0))\n",
    "\n",
    "        self.callbacks.append(CARETensorBoardImage(model=self.keras_model, data=validation_data,\n",
    "                                                   log_dir=str(self.logdir/'logs'/'images'),\n",
    "                                                   n_images=3, prob_out=False))\n",
    "        self._model_prepared = True\n",
    "        \n",
    "    def train(self, X,Y, validation_data, lr, batch_size, epochs, steps_per_epoch):\n",
    "        if not self._model_prepared:\n",
    "            self._prepare_for_training(validation_data, lr)\n",
    "            \n",
    "        training_data = CustomDataGenerator(X,Y,batch_size)\n",
    "        \n",
    "        history = self.keras_model.fit(training_data, validation_data=validation_data,\n",
    "                                       epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                                       callbacks=self.callbacks, verbose=1)\n",
    "        self._training_finished()\n",
    "        return history\n",
    "    \n",
    "    def predict(self, img, axes=None, normalizer=None, resizer=PadAndCropResizer()):\n",
    "        normalizer, resizer = self._check_normalizer_resizer(normalizer, resizer)\n",
    "        axes_net = self.config.axes\n",
    "        if axes is None:\n",
    "            axes = axes_net\n",
    "        axes = axes_check_and_normalize(axes, img.ndim)\n",
    "        axes_net_div_by = tuple((2**self.config.unet_depth if a in 'XYZ' else 1) for a in axes_net)\n",
    "        x = self._make_permute_axes(axes, axes_net)(img)\n",
    "        x = normalizer(x, axes_net)\n",
    "        x = resizer.before(x, axes_net, axes_net_div_by)        \n",
    "        pred = self.keras_model.predict(x[np.newaxis])[0]\n",
    "        pred = resizer.after(pred, axes_net)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    basedir: Path,\n",
    "    modelname: str,\n",
    "    dataset: str,\n",
    "    patch_size: Tuple[int],\n",
    "    epochs: int,\n",
    "    steps: int,\n",
    "    ) -> None:\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (48, 96, 96)\n",
    "modelname = 'care_bcm3d_target1_v2'\n",
    "epochs = 100\n",
    "steps = 100\n",
    "basedir = Path('models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # load and crop out central patch (for simplicity)\n",
    "    X_train = [crop(imread(x), patch_size) for x in sorted(glob(f'training_data/patches-semimanual-raw-64x128x128/train/images/*.tif'))]\n",
    "    Y_train = [crop(imread(y), patch_size) for y in sorted(glob(f'training_data/patches-semimanual-raw-64x128x128/train/target_bacm3d_1/*.tif'))]\n",
    "\n",
    "    # load and crop out central patch (for simplicity)\n",
    "    X_valid = [crop(imread(x), patch_size) for x in sorted(glob(f'training_data/patches-semimanual-raw-64x128x128/valid/images/*.tif'))]\n",
    "    Y_valid = [crop(imread(y), patch_size) for y in sorted(glob(f'training_data/patches-semimanual-raw-64x128x128/valid/target_bacm3d_1/*.tif'))]\n",
    "\n",
    "    # normalize input image\n",
    "    X_train = [normalize(x,1,99.8) for x in tqdm(X_train)]\n",
    "\n",
    "    # normalize input image\n",
    "    X_valid = [normalize(x,1,99.8) for x in tqdm(X_valid)]\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X_train, Y_train = np.expand_dims(np.stack(X_train),-1), np.expand_dims(np.stack(Y_train), -1)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X_valid, Y_valid = np.expand_dims(np.stack(X_valid),-1), np.expand_dims(np.stack(Y_valid), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_std = False\n",
    "common_unet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if high_std:\n",
    "\n",
    "    plt.hist(X_train.std(axis=(1,2,3,4)), 100);\n",
    "\n",
    "    sel = X_train.std(axis=(1,2,3,4))>0.16\n",
    "    X_train = X_train[sel]\n",
    "    Y_train = Y_train[sel]\n",
    "\n",
    "    sel = X_valid.std(axis=(1,2,3,4))>0.16\n",
    "    X_valid = X_valid[sel]\n",
    "    Y_valid = Y_valid[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if common_unet:\n",
    "    config = SegConfig(n_channel_in=1, n_channel_out=1, unet_depth=2)\n",
    "    model = BCM3DModel(config, modelname, basedir=str(basedir))\n",
    "    model\n",
    "\n",
    "    # shuffle data\n",
    "    shuffle_inplace(X_train, Y_train, seed=0)\n",
    "    shuffle_inplace(X_valid, Y_valid, seed=0)\n",
    "\n",
    "    # for demonstration purposes: training only for a very short time here\n",
    "    history = model.train(X_train,Y_train, validation_data=(X_valid,Y_valid),\n",
    "                        lr=4e-4, batch_size=1, epochs=epochs, steps_per_epoch=steps) # Does it improve it batch size = 16?\n",
    "\n",
    "#    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CARE instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import axes_dict, plot_some, plot_history\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.models import Config, CARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plot_some(X_valid[:5],Y_valid[:5])\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit_gpu_memory(fraction=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = 'SZYXC'\n",
    "config = Config(axes, n_channel_in=1, n_channel_out=1, train_steps_per_epoch=100)\n",
    "model = CARE(config, modelname, basedir=basedir)\n",
    "history = model.train(X_train,Y_train, validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csbdeep",
   "language": "python",
   "name": "csbdeep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
