{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-masters",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if tensorflow2:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.__version__.startswith('2'):\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "studied-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tifffile import imsave, imread\n",
    "from stardist.models.model3d import StarDist3D\n",
    "import sys\n",
    "from csbdeep.utils import normalize\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polar-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Eric\\src\\stardist_mpcdf')\n",
    "#sys.path.append(r'D:\\Eric\\stardist_mpcdf')\n",
    "#sys.path.append(r'D:\\Users\\Eric\\src\\stardist_mpcdf')\n",
    "\n",
    "from stardist_mpcdf.data import ImageInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocateOnEmptyGPU():\n",
    "    import os\n",
    "    import re\n",
    "    import numpy as np\n",
    "    from subprocess import check_output\n",
    "\n",
    "    nvidia_smi_output = check_output(['nvidia-smi']).decode(\"utf-8\")\n",
    "    memory_matches = re.findall('\\d+MiB\\s*/\\s*\\d+MiB', nvidia_smi_output)\n",
    "    memory_string = [match.split('MiB')[0] for match in memory_matches]\n",
    "    gpu_memory_usage = list(map(int, memory_string))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(np.argmin(gpu_memory_usage))\n",
    "    print('Run on GPU with ID: {}'.format(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocateOnEmptyGPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agricultural-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_path, dataset_path, output_path, use_overlap, has_overview_plane=False):\n",
    "\n",
    "    stardist_mpcdf_home = Path(os.getcwd()).parent\n",
    "\n",
    "    model_path = Path(model_path)\n",
    "    dataset_path = Path(dataset_path)\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    dataset_name = dataset_path.stem\n",
    "    modelname = model_path.name\n",
    "    model_basedir = model_path.parent\n",
    "\n",
    "    print(f'Read {dataset_path}: ', end='')\n",
    "    tic = time()\n",
    "    assert(dataset_path.is_file())\n",
    "    X = [imread(str(dataset_path))]\n",
    "    \n",
    "    print('{:.2f}s'.format((time() - tic)))\n",
    "    \n",
    "    not has_overview_plane or print('Remove overview plane ...')\n",
    "    \n",
    "    X = [x[1:] if has_overview_plane else x for x in X]\n",
    "    \n",
    "    output_dir = output_path\n",
    "    if use_overlap:\n",
    "        filelist_x = [Path(str(dataset_path).replace('.tif', 'O.tif'))]\n",
    "    else:\n",
    "        filelist_x = [Path(str(dataset_path).replace('.tif', 'P.tif'))]\n",
    "\n",
    "    dz = 400\n",
    "    factor = int(dz/100)    \n",
    "    \n",
    "    print(f'Interpolate z direction by x{factor}: ', end='')\n",
    "    tic = time()\n",
    "    \n",
    "    if not dz is None:\n",
    "        for i, x in enumerate(X):\n",
    "            \n",
    "            new_shape = (x.shape[0]*factor ,  *x.shape[1:])\n",
    "            X[i] = ImageInterpolation(x, factor, new_shape)\n",
    "            \n",
    "    print('{:.2f}s'.format((time() - tic)))\n",
    "    \n",
    "    print(f'New dataset shape: {new_shape}')\n",
    "        \n",
    "\n",
    "    print(f'Normalize dataset:', end=\"\")\n",
    "    tic = time()\n",
    "    axis_norm = (0, 1, 2)\n",
    "    X = [normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X)]\n",
    "    \n",
    "    print('{:.2f}s'.format((time() - tic)))\n",
    "\n",
    "    print(dataset_name)\n",
    "\n",
    "    print('Dataset length: ', len(X))\n",
    "\n",
    "    print('Load model \"{}\"'.format(modelname))\n",
    "    model = StarDist3D(None, name=modelname, basedir=model_basedir)\n",
    "\n",
    "    predict_opts = {'show_tile_progress': True, 'verbose':True}\n",
    "\n",
    "    #max_size = 224 # for 16GB GPU\n",
    "    max_size = 126 # for 11GB GPU\n",
    "    max_size = 112 # for 4GB GPU\n",
    "    max_size = 96\n",
    "    \n",
    "    if use_overlap:\n",
    "        overlap_label = -1\n",
    "    else:\n",
    "        overlap_label = None\n",
    "    \n",
    "    Y_ = []\n",
    "    for x in tqdm(X):\n",
    "        print('Dataset shape: ', x.shape)\n",
    "        print('Dataset size: ', np.size(x))\n",
    "\n",
    "        if np.size(x) <= max_size**3: # Limited by 16GB GPU\n",
    "            y_ = model.predict_instances(x, verbose=True, overlap_label=overlap_label)[0]\n",
    "\n",
    "        else:\n",
    "            n_tiles = tuple(np.max([1, s//max_size]) for s in x.shape)\n",
    "            print('Num tiles: ', n_tiles)\n",
    "            y_ = model.predict_instances(x, verbose=True, overlap_label=overlap_label,\n",
    "                                         n_tiles=n_tiles)[0]\n",
    "        \"\"\"  \n",
    "        else: # Split into 4 pieces (does not support overlap label, very slow ...)\n",
    "            min_overlap=(32, 64, 64)\n",
    "            context=(32, 64, 64)\n",
    "            block_size = tuple(int(np.ceil(s/2)) + o+2*c for s, o, c in zip(x.shape, min_overlap, context))\n",
    "            print('Block size: ', block_size)\n",
    "            y_ = model.predict_instances_big(x,\n",
    "                                              axes='ZYX',\n",
    "                                              block_size=block_size,\n",
    "                                              min_overlap=min_overlap,\n",
    "                                              context=context, show_progress=True,\n",
    "                                              verbose=True,\n",
    "                                              n_tiles=tuple(np.max([1, s//max_size]) for s in x.shape))[0]\n",
    "        \"\"\"\n",
    "        Y_.append(y_)\n",
    "\n",
    "\n",
    "    if not output_dir.is_dir():\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for y, x_path in tqdm(zip(Y_, filelist_x)):\n",
    "        imsave(output_dir / x_path.name, y, compress=9)\n",
    "  \n",
    "\n",
    "      \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dietary-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = sorted(Path(r'Y:\\Daniel\\000_Microscope data\\2020.09.15_CNN3\\kdv1502R_5L_30ms_300gain002\\Pos5').glob('*_ch1_frame0000??_*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-staff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Y:\\Daniel\\000_Microscope data\\2020.09.15_CNN3\\kdv1502R_5L_30ms_300gain002\\Pos5\\kdv1502R_5L_30ms_300gain002_pos5_ch1_frame000001_Nz54.tif: 4.31s\n",
      "Remove overview plane ...\n",
      "Interpolate z direction by x4: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.04s\n",
      "New dataset shape: (216, 1024, 1024)\n",
      "Normalize dataset:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.40s\n",
      "kdv1502R_5L_30ms_300gain002_pos5_ch1_frame000001_Nz54\n",
      "Dataset length:  1\n",
      "Load model \"eva-v1_dz400_rep1\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.763609, nms_thresh=0.3.\n",
      "Dataset shape:  (216, 1024, 1024)\n",
      "Dataset size:  226492416\n",
      "Num tiles:  (2, 10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▍                                                                                 | 1/200 [00:13<44:41, 13.48s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 2/200 [00:18<27:09,  8.23s/it]\u001b[A\n",
      "  2%|█▏                                                                                | 3/200 [00:22<21:44,  6.62s/it]\u001b[A\n",
      "  2%|█▋                                                                                | 4/200 [00:27<18:51,  5.77s/it]\u001b[A\n",
      "  2%|██                                                                                | 5/200 [00:31<17:17,  5.32s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for f in filelist:\n",
    "    main(r\"models\\eva-v1_dz400_rep1\", str(f), 'predictions', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
